---
title: "Ex1_lab5"
author: "Damian Ke & Kyriakos Papadopoulos"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
library(ggplot2)
library(boot)
```

# Assigment 1: Hypothesis testing

### Question 1:
Make a scatterplot of Y versus X and conclude whether the lottery looks random

**Answer 1:**
```{r, echo=FALSE, fig.align='center'}
# Question 1
data = read.csv("lottery.csv", sep = ";")
X = data$Day_of_year
Y = data$Draft_No
df = data.frame(X, Y)

# Making the plot
p = ggplot(df, aes(x = X, y= Y)) + geom_point()
p
```

From the plot we can conclude that the lotery is random as it doesn't seem that it follows a pattern.

### Question 2:
Compute an estimate $\hat{Y}$ of the expected response as a function of X by using a loess smoother (use loess()), put the curve $\hat{Y}$ versus X in the previous 
graph and state again whether the lottery looks random.

**Answer 2: **
```{r, echo=FALSE, warning=FALSE}
model = loess(Y ~ X, df)
predictions = model$fitted

df = data.frame(X, Y, predictions)
p = ggplot(df, aes(x= X, y= predictions)) + 
  geom_line(aes(color="predictions"), size=1.2) +
  geom_point(aes(x = X, y = Y, color="Y")) +
  scale_color_manual(name="Values",
                     breaks=c("predictions", "Y"),
                     values=c("predictions"="red", "Y"="blue"))

p + labs(y="Draft number", x="Day of the year")
```

We can see that our polynomial model follows a decreasing pattern. Taking that into account
we can conclude that the lottery doesn't look random.

### Question 3:
 To check whether the lottery is random, it is reasonable to use test statistics
 $$T = \frac{\hat{Y}(X_b) - \hat{Y}(X_a)}{X_b - X_a}, where X_b = argmax\hat{Y}, X_a = argminx\hat{Y}(X)$$
If this value is significantly greater than zero, then there should be a trend in the data
and the lottery is not random. Estimate the distribution of T by using a non–parametric
bootstrap with B = 2000 and comment whether the lottery is random or not. What is the
p–value of the test?

**Answer 3:**

```{r}
x_b = which(max(predictions) == predictions)
x_a = which(min(predictions) == predictions)

y_xb <- predict(model, x_b)
y_xa <- predict(model, x_a)


test <- (y_xb - y_xa) / (x_b - x_a)

stat1<-function(data, vn){
  
  data1 <- data[vn,]
  model = loess(Draft_No ~ Day_of_year, data1)
  predictions = model$fitted
  x_b = which.max(predictions)
  x_a = which.min(predictions)
  

  test <- (predictions[x_b] - predictions[x_a]) / (data1$Day_of_year[x_b] - 
                                                     data1$Day_of_year[x_a])
  return(test)
}

res <- boot(data, stat1, R=2000)
hist(res$t)
cat("The p-quantile for t=0 of test is ", mean(res$t < 0))
```

Seeing the graph we can suspect that the data is not random because the distribution
is not mainly distributed around 0. If it was mainly distributed around 0 it would
mean that propably the data would be random as we know that if our test is equal to 
0 is random.

### Question 4:

Implement a function depending on data and B that tests the hypothesisH0: Lottery is random versus
H1: Lottery is non–random by using a permutation test with statistics T. The function is to return the p–value of this test. Test this function on our data with B = 2000.

```{r}
permutation <- function(data, B){

    stat=numeric(B)
    n=dim(data)[1]

  for(b in 1:B){
    Gb=sample(df)
    data2 = data
    data2$Draft_No = sample(data$Draft_No, n)

    model = loess(Draft_No ~ Day_of_year, data2)
    predictions = model$fitted
    x_b = which.max(predictions)
    x_a = which.min(predictions)
    test2 <- (predictions[x_b] - predictions[x_a]) / (data2$Day_of_year[x_b] - data2$Day_of_year[x_a])
    stat[b]= test2
}

hist(stat)
return(mean(abs(stat) >= abs(test)))


}

pi_val = permutation(data, 2000)
```
Our pi value is 0.19. That means that we can not reject the null hypothesis for 
significance level of 0.05


### Question 5:
 Make a crude estimate of the power of the test constructed in Step 4:
(a) Generate (an obviously non–random) dataset with n = 366 observations by using same
X as in the original data set and Y(x) = max(0, min(ax + b, 366)), where a = 0.1 and b is normal distribution with mean = 183 and sd = 10
and b is a normal distribution with mean equal to 183 and sd equal to 10.
(b) Plug these data into the permutation test with B = 200 and note whether it was
rejected.
(c) Repeat Steps 5a–5b for a = 0.2, 0.3, . . . , 10.
What can you say about the quality of your test statistics considering the value of the
power?

**Answer 5:**
```{r, echo=FALSE, fig.show='hide'}
a = 0.1
b = rnorm(1, mean = 183, sd = 10)
Y2 = sapply(X, function(x)(max(0, min(a*x + b, 366))))
data5 = data.frame(X, Y2)

colnames(data5) = c("Day_of_year", "Draft_No")
cat("The p value for alpha = 0.1 is ", permutation(data5, 200), "so the null hypothesis
    was rejected")

alphas = seq(0.01, 1, 0.01)
results <- c()
for(a in alphas){

  b = rnorm(1, mean = 183, sd = 10)
  Y3 = sapply(X, function(x)(max(0, min(a*x + b, 366))))
  data6 = data.frame(X, Y3)
  
  colnames(data6) = c("Day_of_year", "Draft_No")
  res = permutation(data6,200)
  results <- append(results, res)
}

```

```{r, echo=FALSE}
cat("The power error is: ", 1 -  sum(results <= 0.05)/ length(results))
```

We can say the that our test statistics considering the value of the power that our test isvery good as the power error is around 0. The power is the error that we fail to correctly reject a false null hypothesis. in our case our data is not random so we should reject the false null hypothesis that the data is random. That's why we have a so small error as we have rejected most of the null hypothesis in the permudations datasets 
that the dataset is random.


# Assignment 2: Bootstrap, jackknife and confidence intervals

# Question 1
Plot the histogram of Price. Does it remind any conventional distribution? Compute the
mean price.
```{r, echo=FALSE}
df = read.csv2("prices1.csv")
p = ggplot(df, aes(x=Price)) +
  geom_histogram(binwidth=150)
p
mean_price = mean(df$Price)
```

The mean price is equal to `r mean_price`

**Answer**
The distribution looks like gamma distribution.

# Question 2
Estimate the distribution of the mean price of the house using bootstrap. Determine the
bootstrap bias–correction and the variance of the mean price. Compute a 95% confidence
interval for the mean price using bootstrap percentile, bootstrap BCa, and first–order
normal approximation.

```{r, echo=FALSE, warning=FALSE}
library(boot)
set.seed(12345)
stat1 = function(data,vn){
  mean(data[vn,]$Price)
}
res=boot(df,stat1,R=1000)
B=1000
t_1 = 2*res$t0-mean(res$t)
var_t = (1/(B-1))*(sum((res$t-mean(res$t))^2))
plot(res)
```
**Clarification** Used formulas are accordingly to the lecture slides.

The mean price from bootstrap is equal to `r res$t0`

95% Confidence interval with bootstrap percentile is equal to: (`r boot.ci(res)$percent[4:5]`)

95% Confidence interval with bootstrap BCa is equal to: (`r boot.ci(res)$bca[4:5]`)

95% Confidence interval with bootstrap  first–order
normal approximation is equal to: (`r boot.ci(res)$normal[1,2:3]`)

Bootstrap bias–correction is equal to: `r t_1`

Bootstrap variance is equal to: `r var_t`

# Question 3
Estimate the variance of the mean price using the jackknife and compare it with the
bootstrap estimate

```{r, echo=FALSE}
n = length(df$Price)
t_j = rep(0,n)
for (j in 1:n){
  t_j[j] = n*mean(df$Price)-(n-1)*mean(df$Price[-j])
}
j_t = mean(t_j)
var_t2 = (1/(n*(n-1)))*sum((t_j-j_t)**2)
```

**Clarification**: n is set equal to the length of the data sample
as according to the course literature when k = 1. 
According to the lecture slides B=n. By testing both options, there is a small difference
between the values.

Jackknife variance is equal to: `r var_t2`
Bootstrap variance is equal to: `r var_t`

**Answer**
The variance of the mean of jackknife is larger than the bootstrap variance of the mean.
The jackknife leaves one of the observations and then calculates the variance
of the new subset for n amount of iterations. Which compared to bootstrap variance of the mean
will overestimate the variance.


## Question 4
Compare the confidence intervals obtained with respect to their length and the location of
the estimated mean in these intervals.
```{r, echo=FALSE, warning=FALSE}
interval = boot.ci(res)
interval_percentile = interval$percent[1,4:5]
interval_bca = interval$bca[1,4:5]
interval_normal = interval$normal[1,2:3]
interval_percentile[3] = interval_percentile[2]-interval_percentile[1]
interval_percentile[4] = (interval_percentile[2]+interval_percentile[1])/2
interval_bca[3] = interval_bca[2]-interval_bca[1]
interval_bca[4] = (interval_bca[2]+interval_bca[1])/2
interval_normal[3] = interval_normal[2]-interval_normal[1]
interval_normal[4] = (interval_normal[2]+interval_normal[1])/2
df_results = t(data.frame(interval_bca,interval_normal,interval_percentile))
colnames(df_results) = c("Lower CI", "Upper CI", "Length","Mean")
rownames(df_results) = c("BCA", "Normal","Percentile")
knitr::kable(df_results)
```

**Answer**
As it can be seen in the table, BCa has the largest length difference.
Thereafter it is  Normal(first–order normal approximation) and lastly Percentile. 
The mean for corresponding intervals are in order of BCA as largest then Percentile and 
lastly Normal (first–order normal approximation


### Appendix

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```
